## Beer-source Kamelet Example

This example shows you how to create a simple beer souce kamelet that retrieve a random beer from the catalog and how to run a simple integration using this kamelet. We will use KameletBinding to bind the `beer-source` to a KafkaTopic `beer-events`, and create a `log-sink` to consume the events from the `beer-events`.

### Create beer-source Kamelet

First of all, we need to define a Kamelet `beer-source.kamelet.yaml`:

`oc apply -f beer-source.kamelet.yaml`

To see the list of available Kamelets on the cluster by running:

`oc get kamelets`

We'll use the source in a small integration `beers.yaml`:

```
- from:
    uri: "kamelet:beer-source?period=5000"
    steps:
      - log: "${body}"
```
By running `kamel run beers.yaml --dev`, you should be able to see the details of the randomly chosen beer in your terminal every five seconds.

## Using Kamelets in an event-driven architecture

We have created a source Kamelet (`beer-source`), what about creating a sink Kamelet? In this section, we will create a sink that consume the source events.

### Create a KafkaTopic
Let's use the `beer-source` to emit "random beers" into a Kafka topic. We should set up with Red Hat AMQ Streams operator. Once it's ready, create a KafkaTopic by running:

`oc apply -f beer-kafkatopic.yaml`

As soon as it's running, let's create a `KameletBinding` to forward the events generated by the source to the KafkaTopic:

`oc apply -f beer-kameletbinding.yaml`

### Create the sink flow

Now we need to create a sink (consumer) that consumes the events and print them out on the screen:

`oc apply -f log-sink.kamelet.yaml`

`log-sink.kamelet.yaml` defines a simple logger.

Now we should create a `KameletBinding` to match the events to the logger:

`oc apply -f log-sink-binding.yaml`

## Let's check the running integration

Let's have a final look at the logs to see the sink action:

`kamel logs log-event-sink`

You should be able to see the details of the chosen beers.

